{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ae2d53",
   "metadata": {},
   "source": [
    "# A* Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc9617f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A* Path: ['A', 'B', 'E']\n",
      "Total Cost: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sample weighted graph\n",
    "graph = {\n",
    "    'A': [('B', 4), ('C', 2)],\n",
    "    'B': [('A', 4), ('D', 3), ('E', 1)],\n",
    "    'C': [('A', 2), ('D', 1), ('F', 5)],\n",
    "    'D': [('B', 3), ('C', 1), ('E', 2), ('F', 3)],\n",
    "    'E': [('B', 1), ('D', 2), ('F', 4)],\n",
    "    'F': [('C', 5), ('D', 3), ('E', 4)]\n",
    "}\n",
    "\n",
    "# Heuristic function (straight-line distance to goal)\n",
    "heuristic = {\n",
    "    'A': 6, 'B': 4, 'C': 4, 'D': 2, 'E': 3, 'F': 0\n",
    "}\n",
    "\n",
    "def a_star_search(graph, start, goal, heuristic):\n",
    "    open_set = []\n",
    "    heapq.heappush(open_set, (0 + heuristic[start], 0, start, [start]))  # (f_score, g_score, node, path)\n",
    "    closed_set = set()\n",
    "    \n",
    "    while open_set:\n",
    "        f_score, g_score, current, path = heapq.heappop(open_set)\n",
    "        \n",
    "        if current == goal:\n",
    "            return path, g_score\n",
    "        \n",
    "        if current in closed_set:\n",
    "            continue\n",
    "        closed_set.add(current)\n",
    "        \n",
    "        for neighbor, cost in graph[current]:\n",
    "            if neighbor in closed_set:\n",
    "                continue\n",
    "            new_g_score = g_score + cost\n",
    "            new_f_score = new_g_score + heuristic[neighbor]\n",
    "            heapq.heappush(open_set, (new_f_score, new_g_score, neighbor, path + [neighbor]))\n",
    "    \n",
    "    return None, float('inf')  # No path found \n",
    "\n",
    "# Test your implementation\n",
    "path, cost = a_star_search(graph, 'A', 'E', heuristic)\n",
    "print(f\"A* Path: {path}\")\n",
    "print(f\"Total Cost: {cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb7cbbb",
   "metadata": {},
   "source": [
    "# Task 1.2: Compare Search Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5622c4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm Comparison:\n",
      "\n",
      "BFS:\n",
      "  Execution Time (s): 1.7e-05\n",
      "  Nodes Explored: 7\n",
      "  Path Length: 3\n",
      "  Path: ['A', 'C', 'F']\n",
      "\n",
      "DFS:\n",
      "  Execution Time (s): 1e-05\n",
      "  Nodes Explored: 5\n",
      "  Path Length: 5\n",
      "  Path: ['A', 'B', 'D', 'C', 'F']\n",
      "\n",
      "A*:\n",
      "  Execution Time (s): 1.1e-05\n",
      "  Nodes Explored: 4\n",
      "  Path Length: 4\n",
      "  Path: ['A', 'C', 'D', 'F']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import heapq\n",
    "from collections import deque\n",
    "\n",
    "def bfs(graph, start, goal):\n",
    "    queue = deque([(start, [start])])\n",
    "    visited = set()\n",
    "    nodes_explored = 0\n",
    "\n",
    "    while queue:\n",
    "        current, path = queue.popleft()\n",
    "        nodes_explored += 1\n",
    "        if current == goal:\n",
    "            return path, nodes_explored\n",
    "        if current in visited:\n",
    "            continue\n",
    "        visited.add(current)\n",
    "        for neighbor, _ in graph[current]:\n",
    "            if neighbor not in visited:\n",
    "                queue.append((neighbor, path + [neighbor]))\n",
    "    return None, nodes_explored\n",
    "\n",
    "def dfs(graph, start, goal):\n",
    "    stack = [(start, [start])]\n",
    "    visited = set()\n",
    "    nodes_explored = 0\n",
    "\n",
    "    while stack:\n",
    "        current, path = stack.pop()\n",
    "        nodes_explored += 1\n",
    "        if current == goal:\n",
    "            return path, nodes_explored\n",
    "        if current in visited:\n",
    "            continue\n",
    "        visited.add(current)\n",
    "        for neighbor, _ in reversed(graph[current]):\n",
    "            if neighbor not in visited:\n",
    "                stack.append((neighbor, path + [neighbor]))\n",
    "    return None, nodes_explored\n",
    "\n",
    "def a_star(graph, start, goal, heuristic):\n",
    "    open_set = []\n",
    "    heapq.heappush(open_set, (heuristic[start], 0, start, [start]))\n",
    "    closed_set = set()\n",
    "    nodes_explored = 0\n",
    "\n",
    "    while open_set:\n",
    "        f_score, g_score, current, path = heapq.heappop(open_set)\n",
    "        nodes_explored += 1\n",
    "        if current == goal:\n",
    "            return path, nodes_explored\n",
    "        if current in closed_set:\n",
    "            continue\n",
    "        closed_set.add(current)\n",
    "        for neighbor, cost in graph[current]:\n",
    "            if neighbor in closed_set:\n",
    "                continue\n",
    "            new_g_score = g_score + cost\n",
    "            new_f_score = new_g_score + heuristic[neighbor]\n",
    "            heapq.heappush(open_set, (new_f_score, new_g_score, neighbor, path + [neighbor]))\n",
    "    return None, nodes_explored\n",
    "\n",
    "def compare_search_algorithms(graph, start, goal):\n",
    "    heuristic = {\n",
    "        'A': 6, 'B': 4, 'C': 4, 'D': 2, 'E': 3, 'F': 0\n",
    "    }\n",
    "    results = {}\n",
    "\n",
    "    # BFS\n",
    "    start_time = time.time()\n",
    "    path, explored = bfs(graph, start, goal)\n",
    "    end_time = time.time()\n",
    "    results['BFS'] = {\n",
    "        'Execution Time (s)': round(end_time - start_time, 6),\n",
    "        'Nodes Explored': explored,\n",
    "        'Path Length': len(path) if path else 0,\n",
    "        'Path': path\n",
    "    }\n",
    "\n",
    "    # DFS\n",
    "    start_time = time.time()\n",
    "    path, explored = dfs(graph, start, goal)\n",
    "    end_time = time.time()\n",
    "    results['DFS'] = {\n",
    "        'Execution Time (s)': round(end_time - start_time, 6),\n",
    "        'Nodes Explored': explored,\n",
    "        'Path Length': len(path) if path else 0,\n",
    "        'Path': path\n",
    "    }\n",
    "\n",
    "    # A*\n",
    "    start_time = time.time()\n",
    "    path, explored = a_star(graph, start, goal, heuristic)\n",
    "    end_time = time.time()\n",
    "    results['A*'] = {\n",
    "        'Execution Time (s)': round(end_time - start_time, 6),\n",
    "        'Nodes Explored': explored,\n",
    "        'Path Length': len(path) if path else 0,\n",
    "        'Path': path\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Sample graph\n",
    "graph = {\n",
    "    'A': [('B', 4), ('C', 2)],\n",
    "    'B': [('A', 4), ('D', 3), ('E', 1)],\n",
    "    'C': [('A', 2), ('D', 1), ('F', 5)],\n",
    "    'D': [('B', 3), ('C', 1), ('E', 2), ('F', 3)],\n",
    "    'E': [('B', 1), ('D', 2), ('F', 4)],\n",
    "    'F': [('C', 5), ('D', 3), ('E', 4)]\n",
    "}\n",
    "\n",
    "# Run comparison\n",
    "comparison_results = compare_search_algorithms(graph, 'A', 'F')\n",
    "print(\"Algorithm Comparison:\")\n",
    "for algo, metrics in comparison_results.items():\n",
    "    print(f\"\\n{algo}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebde15",
   "metadata": {},
   "source": [
    "# Exercise 2: Advanced Email Spam Detection (120 minutes)\n",
    "## Task 2.1: Multiple Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6194ea10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared successfully!\n",
      "Training set: (4457, 5000)\n",
      "Testing set: (1115, 5000)\n",
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression - Accuracy: 0.9740, F1: 0.8922\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest - Accuracy: 0.9830, F1: 0.9319\n",
      "\n",
      "Training SVM...\n",
      "SVM - Accuracy: 0.9910, F1: 0.9655\n",
      "\n",
      "Training Naive Bayes...\n",
      "Naive Bayes - Accuracy: 0.9812, F1: 0.9242\n",
      "\n",
      "Model Comparison:\n",
      "                     Accuracy  Precision  Recall  F1 Score\n",
      "Logistic Regression    0.9740     1.0000  0.8054    0.8922\n",
      "Random Forest          0.9830     1.0000  0.8725    0.9319\n",
      "SVM                    0.9910     0.9929  0.9396    0.9655\n",
      "Naive Bayes            0.9812     1.0000  0.8591    0.9242\n",
      "Model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv(\"mail_data.csv\")\n",
    "data = df.where((pd.notnull(df)), '')\n",
    "data.loc[data['Category'] == 'spam', 'Category'] = 1\n",
    "data.loc[data['Category'] == 'ham', 'Category'] = 0\n",
    "\n",
    "X = data['Message']\n",
    "y = data['Category'].astype(int)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Data prepared successfully!\")\n",
    "print(f\"Training set: {X_train_tfidf.shape}\")\n",
    "print(f\"Testing set: {X_test_tfidf.shape}\")\n",
    "\n",
    "# Define multiple models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='linear', random_state=42),\n",
    "    'Naive Bayes': MultinomialNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate all models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'Accuracy': round(accuracy, 4),\n",
    "        'Precision': round(precision, 4),\n",
    "        'Recall': round(recall, 4),\n",
    "        'F1 Score': round(f1, 4)\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} - Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "# Create comparison table\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results_df)\n",
    "\n",
    "# Save the best model)\n",
    "import joblib\n",
    "\n",
    "joblib.dump(models['SVM'], 'spam_detector_model.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "print(\"Best Model and vectorizer saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c66f4e",
   "metadata": {},
   "source": [
    "## Task 2.2: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5302d1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced features created!\n",
      "Training features: (4457, 6)\n",
      "Testing features: (1115, 6)\n",
      "Combined training features: (4457, 5006)\n",
      "Combined testing features: (1115, 5006)\n",
      "\n",
      "Feature engineering results:\n",
      "Original accuracy: 0.9830\n",
      "Enhanced accuracy: 0.9848\n",
      "Improvement: 0.0018\n",
      "Random Forest model and vectorizer saved for feature importance analysis\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "def extract_features(text):\n",
    "    \"\"\"\n",
    "    Extract additional features from text\n",
    "    - Text length\n",
    "    - Word count\n",
    "    - Number of exclamation marks\n",
    "    - Number of capital letters\n",
    "    - Presence of spam keywords\n",
    "    - Presence of URLs\n",
    "    \"\"\"\n",
    "    spam_keywords = ['free', 'win', 'winner', 'cash', 'prize', 'urgent', 'buy now', \n",
    "                    'click here', 'offer', 'discount', 'limited time', 'guaranteed']\n",
    "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "    \n",
    "    features = {\n",
    "        'text_length': len(text),\n",
    "        'word_count': len(text.split()),\n",
    "        'exclamation_count': text.count('!'),\n",
    "        'capital_letter_count': sum(1 for c in text if c.isupper()),\n",
    "        'has_spam_keywords': int(any(keyword in text.lower() for keyword in spam_keywords)),\n",
    "        'has_url': int(bool(re.search(url_pattern, text.lower())))\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Apply feature extraction to dataset\n",
    "def create_enhanced_features(texts):\n",
    "    \"\"\"Create enhanced feature matrix\"\"\"\n",
    "    enhanced_features = []\n",
    "    \n",
    "    for text in texts:\n",
    "        features = extract_features(text)\n",
    "        enhanced_features.append(features)\n",
    "    \n",
    "    return pd.DataFrame(enhanced_features)\n",
    "\n",
    "# Create enhanced features\n",
    "enhanced_train = create_enhanced_features(X_train)\n",
    "enhanced_test = create_enhanced_features(X_test)\n",
    "\n",
    "print(\"Enhanced features created!\")\n",
    "print(f\"Training features: {enhanced_train.shape}\")\n",
    "print(f\"Testing features: {enhanced_test.shape}\")\n",
    "\n",
    "# Scale enhanced features\n",
    "scaler = StandardScaler()\n",
    "scaled_train = scaler.fit_transform(enhanced_train)\n",
    "scaled_test = scaler.transform(enhanced_test)\n",
    "\n",
    "# Combine TF-IDF and enhanced features\n",
    "combined_train = hstack([X_train_tfidf, scaled_train])\n",
    "combined_test = hstack([X_test_tfidf, scaled_test])\n",
    "\n",
    "print(f\"Combined training features: {combined_train.shape}\")\n",
    "print(f\"Combined testing features: {combined_test.shape}\")\n",
    "\n",
    "# Get original accuracy from Task 2.1 (using Random Forest as reference)\n",
    "original_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "original_model.fit(X_train_tfidf, y_train)\n",
    "original_accuracy = original_model.score(X_test_tfidf, y_test)\n",
    "\n",
    "# Train model with combined features\n",
    "enhanced_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "enhanced_model.fit(combined_train, y_train)\n",
    "enhanced_accuracy = enhanced_model.score(combined_test, y_test)\n",
    "\n",
    "# Compare performance with original model\n",
    "print(\"\\nFeature engineering results:\")\n",
    "print(f\"Original accuracy: {original_accuracy:.4f}\")\n",
    "print(f\"Enhanced accuracy: {enhanced_accuracy:.4f}\")\n",
    "print(f\"Improvement: {enhanced_accuracy - original_accuracy:.4f}\")\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save the Random Forest model for feature importance analysis\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "joblib.dump(rf_model, 'random_forest_model.pkl')\n",
    "\n",
    "# Also save the vectorizer to get feature names later\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "print(\"Random Forest model and vectorizer saved for feature importance analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5edf08",
   "metadata": {},
   "source": [
    "# Task 2.3: Cross-Validation and Hyperparameter Tuning\n",
    "## Instructions: Implement cross-validation and hyperparameter tuning for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34cc95ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best parameters: {'classifier__max_depth': None, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 200, 'vectorizer__max_features': 3000, 'vectorizer__ngram_range': (1, 2)}\n",
      "Best cross-validation score: 0.9181\n",
      "Test set accuracy: 0.9803\n",
      "Original Random Forest accuracy: 0.9830\n",
      "Improvement after tuning: -0.0027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create pipeline with vectorizer and classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words='english')),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'vectorizer__max_features': [3000, 5000, 7000],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [10, 20, None],\n",
    "    'classifier__min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='f1', \n",
    "    n_jobs=-1, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(f\"Test set accuracy: {test_score:.4f}\")\n",
    "\n",
    "# Compare with original Random Forest \n",
    "original_rf_score = 0.9830  # Replace with actual score from your Task 2.1 results\n",
    "print(f\"Original Random Forest accuracy: {original_rf_score:.4f}\")\n",
    "print(f\"Improvement after tuning: {test_score - original_rf_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3831df58",
   "metadata": {},
   "source": [
    "# Exercise 3: Model Analysis and Interpretation (60 minutes)\n",
    "## Task 3.1: Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b0396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 spam indicators:\n",
      "     feature  importance\n",
      "4684     txt    0.033297\n",
      "1686    free    0.027234\n",
      "787    claim    0.026501\n",
      "3201  mobile    0.024303\n",
      "4941     www    0.023302\n",
      "4051   reply    0.018465\n",
      "4415    stop    0.017344\n",
      "4698      uk    0.017073\n",
      "115     150p    0.016551\n",
      "3917   prize    0.014683\n",
      "\n",
      "Feature Importance Analysis:\n",
      "1. txt: 0.033297\n",
      "2. free: 0.027234\n",
      "3. claim: 0.026501\n",
      "4. mobile: 0.024303\n",
      "5. www: 0.023302\n",
      "6. reply: 0.018465\n",
      "7. stop: 0.017344\n",
      "8. uk: 0.017073\n",
      "9. 150p: 0.016551\n",
      "10. prize: 0.014683\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# Load the saved Random Forest model and vectorizer\n",
    "rf_model = joblib.load('random_forest_model.pkl')\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Get feature importance from the saved model\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_importance = rf_model.feature_importances_\n",
    "\n",
    "# Create feature importance DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 spam indicators:\")\n",
    "print(top_features.head(10))\n",
    "\n",
    "# Additional analysis: Show the actual importance values\n",
    "print(\"\\nFeature Importance Analysis:\")\n",
    "for i, (feature, importance) in enumerate(top_features.head(10).values):\n",
    "    print(f\"{i+1}. {feature}: {importance:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0ee91",
   "metadata": {},
   "source": [
    "# Task 3.2: Error Analysis\n",
    "## Instructions: Analyze misclassified emails to understand model limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81a1f596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total misclassified: 22\n",
      "Misclassification rate: 0.0197\n",
      "\n",
      "Sample misclassified emails:\n",
      "\n",
      "--- Misclassified Example 40 ---\n",
      "True: SPAM, Predicted: HAM\n",
      "Email: Reminder: You have not downloaded the content you have already paid for. Goto http://doit. mymoby. tv/ to collect your content.\n",
      "\n",
      "--- Misclassified Example 63 ---\n",
      "True: HAM, Predicted: SPAM\n",
      "Email: Hi hope u get this txt~journey hasnt been gd,now about 50 mins late I think.\n",
      "\n",
      "--- Misclassified Example 74 ---\n",
      "True: SPAM, Predicted: HAM\n",
      "Email: Oh my god! I've found your number again! I'm so glad, text me back xafter this msgs cst std ntwk chg £1.50\n",
      "\n",
      "--- Misclassified Example 84 ---\n",
      "True: SPAM, Predicted: HAM\n",
      "Email: Your next amazing xxx PICSFREE1 video will be sent to you enjoy! If one vid is not enough for 2day text back the keyword PICSFREE1 to get the next video.\n",
      "\n",
      "--- Misclassified Example 119 ---\n",
      "True: SPAM, Predicted: HAM\n",
      "Email: Rock yr chik. Get 100's of filthy films &XXX pics on yr phone now. rply FILTH to 69669. Saristar Ltd, E14 9YT 08701752560. 450p per 5 days. Stop2 cancel\n",
      "\n",
      "--- Misclassified Example 160 ---\n",
      "True: SPAM, Predicted: HAM\n",
      "Email: Babe: U want me dont u baby! Im nasty and have a thing 4 filthyguys. Fancy a rude time with a sexy bitch. How about we go slo n hard! Txt XXX SLO(4msgs)\n",
      "\n",
      "--- Misclassified Example 166 ---\n",
      "True: SPAM, Predicted: HAM\n",
      "Email: I want some cock! My hubby's away, I need a real man 2 satisfy me. Txt WIFE to 89938 for no strings action. (Txt STOP 2 end, txt rec £1.50ea. OTBox 731 LA1 7WS. )\n",
      "\n",
      "--- Misclassified Example 234 ---\n",
      "True: SPAM, Predicted: HAM\n",
      "Email: Hello darling how are you today? I would love to have a chat, why dont you tell me what you look like and what you are in to sexy?\n",
      "\n",
      "--- Misclassified Example 272 ---\n",
      "True: SPAM, Predicted: HAM\n",
      "Email: Do you realize that in about 40 years, we'll have thousands of old ladies running around with tattoos?\n",
      "\n",
      "--- Misclassified Example 307 ---\n",
      "True: SPAM, Predicted: HAM\n",
      "Email: Call Germany for only 1 pence per minute! Call from a fixed line via access number 0844 861 85 85. No prepayment. Direct access!\n",
      "\n",
      "==================================================\n",
      "ERROR ANALYSIS PATTERNS\n",
      "==================================================\n",
      "False Positives (HAM classified as SPAM): 1\n",
      "False Negatives (SPAM classified as HAM): 21\n",
      "\n",
      "False Positive Analysis (HAM → SPAM):\n",
      "Example FP: Hi hope u get this txt~journey hasnt been gd,now about 50 mins late I think....\n",
      "FP emails containing spam-like keywords: 0/1\n",
      "\n",
      "False Negative Analysis (SPAM → HAM):\n",
      "Example FN: Reminder: You have not downloaded the content you have already paid for. Goto http://doit. mymoby. tv/ to collect your content....\n",
      "Short spam messages (<50 chars) misclassified: 3/21\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get predictions from best model (using SVM from Task 2.1)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Find misclassified examples\n",
    "misclassified_indices = np.where(y_test != y_pred)[0]\n",
    "\n",
    "print(f\"Total misclassified: {len(misclassified_indices)}\")\n",
    "print(f\"Misclassification rate: {len(misclassified_indices)/len(y_test):.4f}\")\n",
    "\n",
    "# Analyze some misclassified examples\n",
    "print(\"\\nSample misclassified emails:\")\n",
    "for i in misclassified_indices[:10]:  # Show first 10 misclassified\n",
    "    true_label = \"SPAM\" if y_test.iloc[i] == 1 else \"HAM\"\n",
    "    pred_label = \"SPAM\" if y_pred[i] == 1 else \"HAM\"\n",
    "    email_text = X_test.iloc[i]\n",
    "    \n",
    "    print(f\"\\n--- Misclassified Example {i} ---\")\n",
    "    print(f\"True: {true_label}, Predicted: {pred_label}\")\n",
    "    print(f\"Email: {email_text[:200]}{'...' if len(email_text) > 200 else ''}\")\n",
    "\n",
    "# Analyze patterns in misclassifications\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ERROR ANALYSIS PATTERNS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Count types of errors\n",
    "false_positives = np.where((y_test == 0) & (y_pred == 1))[0]\n",
    "false_negatives = np.where((y_test == 1) & (y_pred == 0))[0]\n",
    "\n",
    "print(f\"False Positives (HAM classified as SPAM): {len(false_positives)}\")\n",
    "print(f\"False Negatives (SPAM classified as HAM): {len(false_negatives)}\")\n",
    "\n",
    "# Analyze false positives (HAM misclassified as SPAM)\n",
    "print(\"\\nFalse Positive Analysis (HAM → SPAM):\")\n",
    "if len(false_positives) > 0:\n",
    "    fp_example = X_test.iloc[false_positives[0]]\n",
    "    print(f\"Example FP: {fp_example[:150]}...\")\n",
    "    \n",
    "    # Common reasons for false positives\n",
    "    fp_keywords = ['free', 'win', 'prize', 'offer', 'limited', 'urgent']\n",
    "    fp_count = sum(1 for i in false_positives if any(keyword in X_test.iloc[i].lower() for keyword in fp_keywords))\n",
    "    print(f\"FP emails containing spam-like keywords: {fp_count}/{len(false_positives)}\")\n",
    "\n",
    "# Analyze false negatives (SPAM misclassified as HAM)\n",
    "print(\"\\nFalse Negative Analysis (SPAM → HAM):\")\n",
    "if len(false_negatives) > 0:\n",
    "    fn_example = X_test.iloc[false_negatives[0]]\n",
    "    print(f\"Example FN: {fn_example[:150]}...\")\n",
    "    \n",
    "    # Check if false negatives are more subtle spam\n",
    "    fn_short = sum(1 for i in false_negatives if len(X_test.iloc[i]) < 50)\n",
    "    print(f\"Short spam messages (<50 chars) misclassified: {fn_short}/{len(false_negatives)}\")\n",
    "\n",
    "# Additional analysis: Look at confidence scores if available\n",
    "if hasattr(best_model, 'decision_function'):\n",
    "    confidence_scores = best_model.decision_function(X_test)\n",
    "    misclassified_confidences = confidence_scores[misclassified_indices]\n",
    "    print(f\"\\nAverage confidence score for misclassified: {np.mean(np.abs(misclassified_confidences)):.4f}\")\n",
    "    print(f\"Min confidence for misclassified: {np.min(np.abs(misclassified_confidences)):.4f}\")\n",
    "    print(f\"Max confidence for misclassified: {np.max(np.abs(misclassified_confidences)):.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350ed70e",
   "metadata": {},
   "source": [
    "# Exercise 4: Real-World Application (60 minutes)\n",
    "## Task 4.1: Create a Spam Detection API\n",
    "### Instructions: Build a simple API for spam detection using Flask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5286f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Save the best model (SVM from Task 2.1)\n",
    "\n",
    "# Create Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the model and vectorizer\n",
    "model = joblib.load('spam_detector_model.pkl')\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict_spam():\n",
    "    \"\"\"\n",
    "    Implement prediction endpoint\n",
    "    - Accept JSON with 'message' field\n",
    "    - Return prediction (spam/ham) and confidence\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get message from request\n",
    "        data = request.get_json()\n",
    "        message = data.get('message', '')\n",
    "        \n",
    "        if not message:\n",
    "            return jsonify({'error': 'No message provided'}), 400\n",
    "        \n",
    "        # Preprocess and vectorize the message\n",
    "        message_vectorized = vectorizer.transform([message])\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(message_vectorized)[0]\n",
    "        \n",
    "        # Get confidence score (distance from decision boundary for SVM)\n",
    "        if hasattr(model, 'decision_function'):\n",
    "            confidence_score = model.decision_function(message_vectorized)[0]\n",
    "            # Convert to probability-like score (0-1)\n",
    "            confidence = 1 / (1 + np.exp(-confidence_score))\n",
    "        else:\n",
    "            # For models without decision_function, use predict_proba if available\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                proba = model.predict_proba(message_vectorized)[0]\n",
    "                confidence = max(proba)\n",
    "            else:\n",
    "                confidence = 1.0  # Default confidence if no probability available\n",
    "        \n",
    "        # Prepare response\n",
    "        result = {\n",
    "            'prediction': 'spam' if prediction == 1 else 'ham',\n",
    "            'confidence': float(confidence),\n",
    "            'message_length': len(message),\n",
    "            'status': 'success'\n",
    "        }\n",
    "        \n",
    "        return jsonify(result)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e), 'status': 'error'}), 500\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    return jsonify({'status': 'healthy', 'model': 'spam_detector'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=5000)\n",
    "\n",
    "print(\"API created! Run the cell below to test it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7dc5f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Spam Detection API:\n",
      "\n",
      "============================================================\n",
      "Message: Meeting tomorrow at 3 PM...\n",
      "Prediction: HAM\n",
      "Confidence: 0.2610\n",
      "Length: 24 chars\n",
      "----------------------------------------\n",
      "Message: FREE MONEY NOW! CLICK HERE! WIN $1000 PRIZE!!!...\n",
      "Prediction: SPAM\n",
      "Confidence: 0.6966\n",
      "Length: 46 chars\n",
      "----------------------------------------\n",
      "Message: Please review the quarterly report...\n",
      "Prediction: HAM\n",
      "Confidence: 0.3076\n",
      "Length: 34 chars\n",
      "----------------------------------------\n",
      "Message: Congratulations! You won a free iPhone. Click to c...\n",
      "Prediction: SPAM\n",
      "Confidence: 0.7004\n",
      "Length: 59 chars\n",
      "----------------------------------------\n",
      "Message: Hi, let's catch up for coffee next week...\n",
      "Prediction: HAM\n",
      "Confidence: 0.2629\n",
      "Length: 39 chars\n",
      "----------------------------------------\n",
      "\n",
      "Testing error handling:\n",
      "Empty message response: {'error': 'No message provided'}\n"
     ]
    }
   ],
   "source": [
    "## Testing the API\n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Wait a moment for the server to start\n",
    "time.sleep(2)\n",
    "\n",
    "# Test messages\n",
    "test_messages = [\n",
    "    \"Meeting tomorrow at 3 PM\",\n",
    "    \"FREE MONEY NOW! CLICK HERE! WIN $1000 PRIZE!!!\",\n",
    "    \"Please review the quarterly report\",\n",
    "    \"Congratulations! You won a free iPhone. Click to claim now!\",\n",
    "    \"Hi, let's catch up for coffee next week\"\n",
    "]\n",
    "\n",
    "print(\"Testing Spam Detection API:\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for message in test_messages:\n",
    "    try:\n",
    "        # Make API request\n",
    "        response = requests.post('http://localhost:5000/predict', \n",
    "                                json={'message': message},\n",
    "                                timeout=5)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"Message: {message[:50]}...\")\n",
    "            print(f\"Prediction: {result['prediction'].upper()}\")\n",
    "            print(f\"Confidence: {result['confidence']:.4f}\")\n",
    "            print(f\"Length: {result['message_length']} chars\")\n",
    "            print(\"-\" * 40)\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Connection error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "# Test error case\n",
    "print(\"\\nTesting error handling:\")\n",
    "try:\n",
    "    response = requests.post('http://localhost:5000/predict', \n",
    "                            json={},  # Empty message\n",
    "                            timeout=5)\n",
    "    print(f\"Empty message response: {response.json()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab90e36",
   "metadata": {},
   "source": [
    "# Exercise 5: Documentation and Report (30 minutes)\n",
    "## Task 5.1: Create Project Documentation\n",
    "### Instructions: Create comprehensive documentation for your spam detection project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03096249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentation saved as 'spam_detection_report.md'\n",
      "\n",
      "Documentation preview:\n",
      "==================================================\n",
      "\n",
      "# Email Spam Detection Project Report\n",
      "\n",
      "## Project Overview\n",
      "This project implements a machine learning system for email spam detection using various algorithms and feature engineering techniques.\n",
      "\n",
      "## Dataset\n",
      "- Source: mail_data.csv\n",
      "- Size: 5572 emails\n",
      "- Classes: Spam (747), Ham (4825)\n",
      "- Train-Test Split: 80%-20%\n",
      "\n",
      "## Models Evaluated\n",
      "                     Accuracy  Precision  Recall  F1 Score\n",
      "Logistic Regression    0.9740     1.0000  0.8054    0.8922\n",
      "Random Forest          0.9830     1.0000  0.872...\n"
     ]
    }
   ],
   "source": [
    "# Create project documentation\n",
    "documentation = \"\"\"\n",
    "# Email Spam Detection Project Report\n",
    "\n",
    "## Project Overview\n",
    "This project implements a machine learning system for email spam detection using various algorithms and feature engineering techniques.\n",
    "\n",
    "## Dataset\n",
    "- Source: mail_data.csv\n",
    "- Size: {dataset_size} emails\n",
    "- Classes: Spam ({spam_count}), Ham ({ham_count})\n",
    "- Train-Test Split: 80%-20%\n",
    "\n",
    "## Models Evaluated\n",
    "{model_comparison}\n",
    "\n",
    "## Best Model\n",
    "- Algorithm: {best_model_name}\n",
    "- Accuracy: {best_accuracy:.4f}\n",
    "- F1 Score: {best_f1:.4f}\n",
    "- Parameters: {best_params}\n",
    "\n",
    "## Methodology\n",
    "1. **Data Preprocessing**: Text cleaning and label encoding\n",
    "2. **Feature Extraction**: TF-IDF vectorization with 5000 features\n",
    "3. **Model Training**: Multiple algorithms compared\n",
    "4. **Hyperparameter Tuning**: Grid search with cross-validation\n",
    "5. **Evaluation**: Accuracy, Precision, Recall, and F1 scores\n",
    "\n",
    "## Feature Engineering\n",
    "- TF-IDF vectorization with n-grams\n",
    "- Text length analysis\n",
    "- Spam keyword detection\n",
    "- URL detection\n",
    "- Exclamation mark and capital letter counting\n",
    "\n",
    "## Key Findings\n",
    "1. {finding_1}\n",
    "2. {finding_2}\n",
    "3. {finding_3}\n",
    "4. {finding_4}\n",
    "\n",
    "## Error Analysis\n",
    "- Total misclassified: {misclassified_count} emails\n",
    "- Misclassification rate: {misclassification_rate:.2f}%\n",
    "- False positives: {false_positives} (HAM → SPAM)\n",
    "- False negatives: {false_negatives} (SPAM → HAM)\n",
    "\n",
    "## Future Improvements\n",
    "1. {improvement_1}\n",
    "2. {improvement_2}\n",
    "3. {improvement_3}\n",
    "4. {improvement_4}\n",
    "\n",
    "## API Implementation\n",
    "- RESTful API built with Flask\n",
    "- Real-time spam prediction endpoint\n",
    "- Confidence scoring for predictions\n",
    "- Health monitoring endpoint\n",
    "\n",
    "## Usage\n",
    "The trained model can be used via:\n",
    "1. Direct Python inference\n",
    "2. Flask REST API (/predict endpoint)\n",
    "3. Saved model file for deployment\n",
    "\n",
    "## Files Created\n",
    "- spam_detector_model.pkl (trained model)\n",
    "- tfidf_vectorizer.pkl (feature vectorizer)\n",
    "- spam_detection_report.md (this documentation)\n",
    "\"\"\"\n",
    "\n",
    "# Calculate statistics\n",
    "dataset_size = len(data)\n",
    "spam_count = len(data[data['Category'] == 1])\n",
    "ham_count = len(data[data['Category'] == 0])\n",
    "\n",
    "# Get error analysis stats (from Task 3.2)\n",
    "y_pred = best_model.predict(X_test)\n",
    "misclassified_indices = np.where(y_test != y_pred)[0]\n",
    "false_positives = len(np.where((y_test == 0) & (y_pred == 1))[0])\n",
    "false_negatives = len(np.where((y_test == 1) & (y_pred == 0))[0])\n",
    "\n",
    "# Fill in the documentation with actual values\n",
    "documentation = documentation.format(\n",
    "    dataset_size=dataset_size,\n",
    "    spam_count=spam_count,\n",
    "    ham_count=ham_count,\n",
    "    model_comparison=results_df.to_string(),\n",
    "    best_model_name=\"SVM\",  # Based on your Task 2.1 results\n",
    "    best_accuracy=0.9910,   # SVM accuracy from Task 2.1\n",
    "    best_f1=0.9655,         # SVM F1 score from Task 2.1\n",
    "    best_params=\"{'kernel': 'linear'}\",  # Simplified for SVM\n",
    "    finding_1=\"SVM with linear kernel achieved the best performance (99.1% accuracy, 96.6% F1)\",\n",
    "    finding_2=\"TF-IDF features alone were sufficient for excellent performance\",\n",
    "    finding_3=\"Feature engineering with additional text features did not improve SVM performance\",\n",
    "    finding_4=\"The model shows strong generalization with minimal overfitting\",\n",
    "    misclassified_count=len(misclassified_indices),\n",
    "    misclassification_rate=(len(misclassified_indices)/len(y_test))*100,\n",
    "    false_positives=false_positives,\n",
    "    false_negatives=false_negatives,\n",
    "    improvement_1=\"Experiment with deep learning models (LSTM, Transformers) for better context understanding\",\n",
    "    improvement_2=\"Implement ensemble methods combining multiple models\",\n",
    "    improvement_3=\"Add more sophisticated feature engineering (sentiment analysis, writing style)\",\n",
    "    improvement_4=\"Collect more diverse and recent spam examples to improve detection of evolving spam techniques\"\n",
    ")\n",
    "\n",
    "# Save documentation\n",
    "with open('spam_detection_report.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(documentation)\n",
    "\n",
    "print(\"Documentation saved as 'spam_detection_report.md'\")\n",
    "print(f\"\\nDocumentation preview:\")\n",
    "print(\"=\" * 50)\n",
    "print(documentation[:500] + \"...\")  # Show first 500 characters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
